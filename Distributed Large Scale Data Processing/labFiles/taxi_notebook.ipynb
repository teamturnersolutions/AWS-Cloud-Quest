{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09515658-0371-440f-9f38-3586e89f6894",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Step 1 - Import required modules and dependencies.\n",
    "import sys\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import * \n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfec21e-bded-46a1-97fc-7fcdc46fa46e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Step 2 - Create the Apache Spark application.\n",
    "spark =  SparkSession.builder.appName(\"fare-data\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b469239-c482-468a-9b4d-bbae6a47b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3 - replace BUCKETNAME with the S3 bucket name from the previous lab step.\n",
    "#Ex. 'fare-data-ingest-1234567-us-east-1'\n",
    "dataBucket = 'BUCKETNAME'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cec1fc4-0daa-42c8-91f7-8ae528e194bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Step 4 - Read the fare data file from the data lake and import it into the cluster for processing.\n",
    "df = spark.read.csv(\"s3://\"+dataBucket+\"/data/ingest/fare_data.csv\", header=True, inferSchema=False).select('transaction_date', 'fare', 'pickup_time', 'duration_sec', 'car_number', 'pickup_location', 'dropoff_location')\n",
    "df.sort(df.transaction_date, ascending=True).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f3bbf5-1cc7-4135-bf30-b4bdf67ba063",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Step 5 - Look up the total number of records in the file.\n",
    "(\"Total number of records: \" + str(df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d577552-a991-44b1-b854-47e9bf6f8d24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Step 6 - Using Apache Spark, find rides where duration was longer than 5 minutes.\n",
    "dfVol = df.filter( (df.duration_sec > 300)).sort(df.duration_sec, ascending=False)\n",
    "dfVol.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ba68e1-58f0-42d9-8a60-516a3137ce33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Step 7 - As an alternative to Spark, use SQL to query the data within the cluster.\n",
    "#Create a view called fare_date_sql for SQL queries\n",
    "df.createOrReplaceTempView(\"fare_data_sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a0db45-cd39-442f-8b67-93200d62d23f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Step 8 - Run a SQL query on the created query view.\n",
    "dfSql = spark.sql(\"SELECT *  FROM fare_data_sql WHERE duration_sec > 600 AND pickup_location = 'Data_Analytics_Island' and dropoff_location = 'Cloud_Isle' and fare > 15.00 ORDER BY fare DESC LIMIT 10\")\n",
    "dfSql.sort(dfSql.car_number, ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1994f79d-4ac1-4111-88af-e27134688f70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Step 9 - Export the data to a Glue table in order to allow others to query the data using Athena.\n",
    "df.write.format(\"parquet\").mode(\"overwrite\").option(\"path\", \"s3://\"+dataBucket+\"/data/processed/\").saveAsTable(\"default.rides_table\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1866e0-39dc-4db8-aabe-04420c02982f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
